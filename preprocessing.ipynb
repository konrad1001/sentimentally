{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BTVmxnxmysH3kHPa_yfuJ_W5Z8jywXZC",
      "authorship_tag": "ABX9TyMAoJjdG557WC9PAMjHkShc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konrad1001/sentimentally/blob/master/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the CSV file\n",
        "First step is to read our csv file into a pandas dataframe."
      ],
      "metadata": {
        "id": "n1686SgEseww"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "RUK1JuCwri-X"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 20000x6000 start: 15:47 end 15:58\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/computers/IMDB Dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set constants\n",
        "\n",
        "NUMBER_OF_DOCUMENTS = 40000\n",
        "NUMBER_OF_WORDS = 8000\n"
      ],
      "metadata": {
        "id": "U9zjCXhIIzNM"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Basic Cleaning\n",
        "\n",
        "Stripping non alphabet characters, converting to lowercase, and removing the html tags left over."
      ],
      "metadata": {
        "id": "CUp5eAOrtMpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "df = df[:NUMBER_OF_DOCUMENTS]\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', ' ', x))   #remove non-alphabets\n",
        "df['review'] = df['review'].apply(lambda x: x.lower())  #convert to lowercase\n",
        "df['review'] = df['review'].apply(lambda x: re.sub(r'br', '', x))  #remove pesky leftover <br> tags\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "PzUKTuhqtFiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cf4186f-326a-438a-9bee-2c0358ce9406"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment\n",
            "0      one of the other reviewers has mentioned that ...  positive\n",
            "1      a wonderful little production          the fil...  positive\n",
            "2      i thought this was a wonderful way to spend ti...  positive\n",
            "3      basically there s a family where a little boy ...  negative\n",
            "4      petter mattei s  love in the time of money  is...  positive\n",
            "...                                                  ...       ...\n",
            "39995  this was a marvelously funny comedy with a gre...  positive\n",
            "39996  there is no plot  there are no central charact...  positive\n",
            "39997  this show is awesome  i love all the actors  i...  positive\n",
            "39998  the fact that this movie has been entitled to ...  negative\n",
            "39999  i have to confess that i am severely disappoin...  negative\n",
            "\n",
            "[40000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import dictionary"
      ],
      "metadata": {
        "id": "UGSyondZt2Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import terminal_size\n",
        "#import dictionary\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class Dictionary:\n",
        "    FILE_PATH = \"/content/drive/MyDrive/computers/dictionary.txt\"\n",
        "    def __init__(self, length) -> None:\n",
        "      self.length = length\n",
        "      self.dictionary = np.array([])\n",
        "      self.document_frequency_array = np.zeros(length)\n",
        "      self.length = length\n",
        "      self.load(self.FILE_PATH)\n",
        "\n",
        "    def load(self, filename: str) -> None:\n",
        "      self.dictionary = np.loadtxt(filename, dtype=str)[:self.length]\n",
        "\n",
        "    def get(self, index: int) -> str:\n",
        "      return self.dictionary[index]\n",
        "\n",
        "    def get_index(self, word: str) -> int:\n",
        "        try:\n",
        "            return np.where(self.dictionary == word)[0][0]\n",
        "        except IndexError:\n",
        "            return -1\n",
        "\n",
        "    def get_size(self) -> int:\n",
        "      return self.length\n",
        "\n",
        "    def encode(self, vector):\n",
        "      encoded_vector = np.zeros(self.length)\n",
        "      term_frequency = np.zeros(self.length)\n",
        "      for index in vector:\n",
        "        if index != -1:\n",
        "          encoded_vector[index] += 1\n",
        "          term_frequency[index] = 1\n",
        "\n",
        "      self.document_frequency_array += term_frequency\n",
        "\n",
        "      return encoded_vector\n",
        "\n",
        "    def get_document_frequency(self):\n",
        "      return self.document_frequency_array\n"
      ],
      "metadata": {
        "id": "bKW0BbiJt2UD"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert to a Tokenised vector\n",
        "While we're at it lets keep a track of how long each review is, how many words make it up. This will be useful for calculating the term frequnecy"
      ],
      "metadata": {
        "id": "IUxYCecmux3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "d = Dictionary(length=NUMBER_OF_WORDS) #change\n",
        "\n",
        "df['review'] = df['review'].apply(lambda x: x.split())\n",
        "df['review'] = df['review'].apply(lambda x: [d.get_index(word) for word in x]) #remove words not in dictionary and tokenize\n",
        "df['review'] = df['review'].apply(lambda x: [val for val in x if val != -1])\n",
        "df['length'] = df['review'].apply(lambda x: len(x))\n",
        "#df = df[df['review'] != -1]\n",
        "\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siiSp6U6uyIq",
        "outputId": "95102a53-7885-4c4e-a6f3-26c7b3fd0a30"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment  length\n",
            "0      [44, 1, 0, 45, 39, 2783, 9, 149, 3494, 108, 26...  positive     271\n",
            "1      [4, 2766, 397, 883, 0, 3844, 7, 173, 173, 370,...  positive     142\n",
            "2      [13, 990, 11, 29, 4, 2766, 202, 3, 2918, 49, 8...  positive     144\n",
            "3      [5270, 62, 89, 4, 261, 158, 4, 397, 1392, 6148...  negative     112\n",
            "4      [89, 369, 5, 0, 49, 1, 390, 7, 4, 7024, 676, 3...  positive     202\n",
            "...                                                  ...       ...     ...\n",
            "39995  [11, 29, 4, 2346, 3312, 12, 4, 208, 2393, 371,...  positive     115\n",
            "39996  [62, 7, 47, 3869, 62, 19, 47, 685, 2085, 62, 1...  positive     241\n",
            "39997  [11, 267, 7, 4490, 13, 369, 24, 0, 5360, 15, 3...  positive     127\n",
            "39998  [0, 853, 9, 11, 489, 39, 84, 3962, 3, 0, 126, ...  negative     217\n",
            "39999  [13, 25, 3, 9, 13, 83, 11, 291, 33, 5, 47, 202...  negative     222\n",
            "\n",
            "[40000 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encode\n",
        "We can now convert our token vectors into a bag of words."
      ],
      "metadata": {
        "id": "UtBwffkLz9C_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['review'] = df['review'].apply(lambda x: d.encode(x))\n"
      ],
      "metadata": {
        "id": "ADsYrJ5Wz9bt"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compute Term Frequency, Inverse Document Frequency"
      ],
      "metadata": {
        "id": "5VFC8RYM-Yo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TF(vector):\n",
        "  total_number_of_terms = np.sum(vector)\n",
        "  return vector / total_number_of_terms\n",
        "\n",
        "def IDF(vector):\n",
        "  N_documents_in_corpus = np.full(NUMBER_OF_WORDS, NUMBER_OF_DOCUMENTS)\n",
        "  N_documents_containing_term = d.get_document_frequency() + 1\n",
        "\n",
        "  return np.log(N_documents_in_corpus / N_documents_containing_term)\n",
        "\n",
        "def TF_IDF(vector):\n",
        "  return TF(vector) * IDF(vector)\n",
        "\n",
        "computed_TFIDF = pd.DataFrame(df['sentiment'])\n",
        "computed_TFIDF['review as TFIDF'] = df['review'].apply(lambda x: TF_IDF(x))\n",
        "\n",
        "positive = computed_TFIDF[df['sentiment']=='positive']\n",
        "negative = computed_TFIDF[df['sentiment']=='negative']\n"
      ],
      "metadata": {
        "id": "qBRLEbuL-efz"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Output to NPZ files\n",
        "Output to the numpy format that will let us quickly access the values later."
      ],
      "metadata": {
        "id": "v3mOyScFHshW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DIMENSIONS = str(NUMBER_OF_DOCUMENTS) + \"x\" + str(NUMBER_OF_WORDS)\n",
        "#computed_TFIDF.to_csv('/content/drive/MyDrive/computers/TFIDF' + DIMENSIONS + '.csv', index=False)\n",
        "\n",
        "np.savez('/content/drive/MyDrive/computers/Sentimentally/positiveTFIDF' + DIMENSIONS + '.npz', *positive['review as TFIDF'].tolist())\n",
        "np.savez('/content/drive/MyDrive/computers/Sentimentally/negativeTFIDF' + DIMENSIONS + '.npz', *negative['review as TFIDF'].tolist())\n",
        "\n"
      ],
      "metadata": {
        "id": "jXOblcD3HuYf"
      },
      "execution_count": 105,
      "outputs": []
    }
  ]
}